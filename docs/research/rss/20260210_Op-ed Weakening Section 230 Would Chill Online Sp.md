# Op-ed: Weakening Section 230 Would Chill Online Speech

**Source:** rss
**URL:** https://www.eff.org/deeplinks/2026/02/op-ed-weakening-section-230-would-chill-online-speech
**Added:** 2026-02-10T14:57:21.082330
**Relevance:** 5.0/10
**Priority:** low

## Summary

Discusses legal protections for online platforms that enable user-generated content, highlighting how legal frameworks impact technology platforms' ability to host and facilitate communication.

## Original Content

(This appeared as an op-ed published Friday, Feb. 6 in the Daily Journal, a California legal newspaper.) Section 230, “the 26 words that created the internet,” was enacted 30 years ago this week. It was no rush-job—rather, it was the result of wise legislative deliberation and foresight, and it remains the best bulwark to protect free expression online. The internet lets people everywhere connect, share ideas and advocate for change without needing immense resources or technical expertise. Our unprecedented ability to communicate online—on blogs, social media platforms, and educational and cultural platforms like Wikipedia and the Internet Archive—is not an accident. In writing Section 230, Congress recognized that for free expression to thrive on the internet, it had to protect the services that power users’ speech. Section 230 does this by preventing most civil suits against online services that are based on what users say. The law also protects users who act like intermediaries when they, for example, forward an email, retweet another user or host a comment section on their blog. The merits of immunity, both for internet users who rely on intermediaries—from ISPs to email providers to social media platforms, and for internet users who are intermediaries—are readily apparent when compared with the alternatives. One alternative would be to provide no protection at all for intermediaries, leaving them liable for anything and everything anyone says using their service. This legal risk would essentially require every intermediary to review and legally assess every word, sound or image before it’s published—an impossibility at scale, and a death knell for real-time user-generated content. Another option: giving protection to intermediaries only if they exercise a specified duty of care, such as where an intermediary would be liable if they fail to act reasonably in publishing a user’s post. But negligence and other objective standards are almost always insufficient to 

## Matched Goals

improve_architecture

## Analysis

Provides insight into platform legal considerations that might be relevant for managing The David Project's interactions and user content policies, though not directly technical
